Below is the quick fix to make python 3 able to run pypub to generate epub, in my quick test it works but may causes bug.

[1]
Change `from epub import Epub` to `from .epub import Epub` in ~/.local/lib/python3.6/site-packages/pypub/__init__.py

[2]
Change `import urlparse` to `from urllib.parse import urlparse` in ~/.local/lib/python3.6/site-packages/pypub/chapter.py

[3] 
import sys, os, pkgutil
sys.path.append(os.path.dirname(pkgutil.get_loader("pypub").get_filename()))
, in blogspot-downloader.py or ~/.local/lib/python3.6/site-packages/pypub/__init__.py

[4]
try:
  basestring
except NameError:
  basestring = str
, in ~/.local/lib/python3.6/site-packages/pypub/clean.py

[5]
change `for attribute in attribute_dict.keys():` to `for attribute in list(attribute_dict):`
, in ~/.local/lib/python3.6/site-packages/pypub/clean.py

[6]
comment out this part and add this first line:
unformatted_html_unicode_string = root.prettify(encoding='utf-8', formatter='html')
#unformatted_html_unicode_string = unicode(root.prettify(encoding='utf-8',
##                                                        formatter=EntitySubstitution.substitute_html),
##                                          encoding='utf-8')
# fix <br> tags since not handled well by default by bs4
##unformatted_html_unicode_string = unformatted_html_unicode_string.replace('<br>', '<br/>')
# remove &nbsp; and replace with space since not handled well by certain e-readers
##unformatted_html_unicode_string = unformatted_html_unicode_string.replace('&nbsp;', ' ')
return unformatted_html_unicode_string
, in ~/.local/lib/python3.6/site-packages/pypub/clean.py

[7]
comment out this:
#try:
#    assert isinstance(html_unicode_string, basestring)
#except AssertionError:
#    raise TypeError
, in ~/.local/lib/python3.6/site-packages/pypub/clean.py

[8]
#unicode_string = unicode(root.prettify(encoding='utf-8', formatter='html'), encoding='utf-8')
unicode_string = root.prettify(encoding='utf-8', formatter='html')
, in ~/.local/lib/python3.6/site-packages/pypub/clean.py

[9]
comment out this:
    # Close singleton tag_dictionary
    #for tag in constants.SINGLETON_TAG_LIST:
    #    unicode_string = unicode_string.replace(
    #            '<' + tag + '/>',
    #            '<' + tag + ' />')
    return unicode_string
, in ~/.local/lib/python3.6/site-packages/pypub/clean.py

[10]
comment out this:
    def _validate_input_types(self, content, title):
        #try:
        #    assert isinstance(content, basestring)
        #except AssertionError:
        #    raise TypeError('content must be a string')
        #try:
        #    assert isinstance(title, basestring)
        #except AssertionError:
        #    raise TypeError('title must be a string')
, in ~/.local/lib/python3.6/site-packages/pypub/chapter.py

[11]
Add first line and comment out the rest:
unformatted_html_unicode_string = self._content_tree.prettify(encoding='utf-8', formatter='html')
#unformatted_html_unicode_string = unicode(self._content_tree.prettify(encoding='utf-8',
#                                                                      formatter=EntitySubstitution.substitute_html),
#                                          encoding='utf-8')
#unformatted_html_unicode_string = unformatted_html_unicode_string.replace('<br>', '<br/>')
self.content = unformatted_html_unicode_string
, in ~/.local/lib/python3.6/site-packages/pypub/chapter.py

[12]
with open(file_name, 'wb') as f:
    #f.write(self.content.encode('utf-8'))
    f.write(self.content
, in ~/.local/lib/python3.6/site-packages/pypub/chapter.py

[13]
        def read_template():
            with open(self.template_file, 'r') as f:
                #template = f.read().decode('utf-8')
                template = f.read()
            return jinja2.Template(template)
, in ~/.local/lib/python3.6/site-packages/pypub/epub.py

[14]
    for value in lists.values():
        #assert isinstance(value, list)
        if list_length is None:
            list_length = len(value)
        else:
            assert len(value) == list_length
, in ~/.local/lib/python3.6/site-packages/pypub/epub.py

[15]
def create_zip_archive(epub_name):
    #try:
    #    assert isinstance(epub_name, basestring) or epub_name is None
    #except AssertionError:
    #    raise TypeError('epub_name must be string or None')
, in ~/.local/lib/python3.6/site-packages/pypub/epub.py

[16]
Add `from urllib.parse import urljoin` on top of ~/.local/lib/python3.6/site-packages/pypub/chapter.py

    def _get_image_urls(self):
        image_nodes = self._content_tree.find_all('img')
        raw_image_urls = [node['src'] for node in image_nodes if node.has_attr('src')]
        #full_image_urls = [urlparse.urljoin(self.url, image_url) for image_url in raw_image_urls]
        full_image_urls = [urljoin(self.url, image_url) for image_url in raw_image_urls]

, in ~/.local/lib/python3.6/site-packages/pypub/chapter.py

[17] 
def get_image_type(url):
    url = url.lower() #add this
    for ending in ['jpg', 'jpeg', '.gif', '.png']: #add command between .gif and .png !!!
        if url.endswith(ending):
            return ending
    else:
        try:
            f, temp_file_name = tempfile.mkstemp()
            urllib.request.urlretrieve(url, temp_file_name) #add this 
            #urllib.urlretrieve(url, temp_file_name) #comment out this
, in  ~/.local/lib/python3.6/site-packages/pypub/chapter.py




[18]
                if title_node is not None:
                    #title = unicode(title_node.string)
                    title = title_node.string
, in ~/.local/lib/python3.6/site-packages/pypub/chapter.py


[19] #image extension checking should lower() first to reduce unncessary url request to detect image type
    def get_image_type(url):
        url = url.lower() #add this
        for ending in ['jpg', 'jpeg', '.gif', '.png', '.bmp']: #add missing comma between '.gif' and '.png' #add .bmp
            if url.endswith(ending) or ((ending + '?') in url): #add (ending + '?') checking or else not showing image end with ? wichh contains inner html img src, and the imghdr will not recognize it but ePUB editor and web browser able to render it.
                return ending 
, in ~/.local/lib/python3.6/site-packages/pypub/chapter.py


[20] #To fix missing sample code in ePUB, you should add this 2 tags manually in pypub_module_path/pypub/constants.py (Test case: https://security.googleblog.com/2009/03/reducing-xss-by-way-of-automatic.html), and also add "style" tag to make custom image padding 5px (in code) works:

    SUPPORTED_TAGS = {
        'code': [],
        ...
        'figure': [],
        ...
	'kbd': [], #hole, https://www.crummy.com/software/BeautifulSoup/bs3/documentation.html#Parsing%20HTML 
        ...
        'pre': [],
        ...
        'samp': [], #hole, https://www.crummy.com/software/BeautifulSoup/bs3/documentation.html#Parsing%20HTML 
        ...
        'style': ['display', 'padding', 'max-height', 'max-width'],
        ...
	'table': ['width', 'cellspacing', 'cellpadding', 'border',  'align'], #hole
	'td': ['width', 'height', 'bgcolor'], #hole
	'tr': ['width', 'height', 'bgcolor'], #hole 

[21] Set timeout or else it stuck forever, and also add allow_redirects=True:

    $ grep -n requests\.g /home/xiaobai/.local/lib/python3.6/site-packages/pypub/chapter.py
    70:            requests_object = requests.get(image_url, headers=request_headers, allow_redirects=True)
    241:            request_object = requests.get(url, headers=self.request_headers, allow_redirects=True)


[22] Change this create_html_from_fragment() inside pypub/clean.py, from:

    try:
	assert isinstance(tag, bs4.element.Tag)
    except AssertionError:
	raise TypeError
    try:
	assert tag.find_all('body') == []
    except AssertionError:
	raise ValueError

    soup = BeautifulSoup('<html><head></head><body></body></html>', 'html.parser')
    soup.body.append(tag)
    return soup

to:
    #try:
    #    # hole: this is wrong bcoz web browser will auto replace first </html>(if only 2 </html>) with <html>, while <body> still appear.
    #e.g. http://slae.tehwinsam.com/7/assignment7.html
    #    assert tag.find_all('body') == []
    #except AssertionError:
    #    raise ValueError
    if tag.find_all('body') == []:
        soup = BeautifulSoup('<html><head></head><body></body></html>', 'html.parser')
        soup.body.append(tag)
    else:
        soup = BeautifulSoup('<html></html>', 'html.parser')
        soup.html.append(tag)
    return soup

[23] To fix web browser too old error page, edit pypub/chapter.py, increase Firefox version from 31 to newer number, i.e. 1000000 in my example:

    def __init__(self, clean_function=clean.clean):
        self.clean_function = clean_function
        #UA causes too old web browser page, e.g. https://huanlan.zhihu.com/p/12345
        user_agent = r'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/1000000.0'
        self.request_headers = {'User-Agent': user_agent}

[24] To fix charset encoding issues, e.g. gb2312 charset defined in meta tags not showing properly, just edit pypub/chapter.py:

#Add this global functions:

import re
def hole_meta_encoding(soup):
    if soup and soup.meta:
        encod = soup.meta.get('charset')
        if encod == None:
            encod = soup.meta.get('content-type')
            if encod == None:
                content = soup.meta.get('content')
                match = re.search('charset=(.*)', content)
                if match:
                    encod = match.group(1)
                else:
                    return None #raise ValueError('unable to find encoding')
        return encod

Change:
	unicode_string = request_object.text
	return self.create_chapter_from_string(unicode_string, url, title)
to:
	#unicode_string = request_object.text
	return self.create_chapter_from_string(None, url, title, request_object=request_object)

Replace `create_chapter_from_string` function code with (Don't change the part after title_node = root.titl, which included unicode() in python 2):

    def create_chapter_from_string(self, html_string, url=None, title=None, request_object=None):
        """
        # Same description
        """
        if request_object:
            # Test case: https://new.qq.com/omn/20180816/20180816A0A0D0.html which return headers "content-type: text/html; charset=GB2312"
            # ... shouldn't make it utf-8
            if not request_object.encoding: # just in case, default depends on header content-type(alternative to html meta)
                request_object.encoding = 'utf-8'
            html_string = request_object.text
        elif not html_string: #if 404, request_object will None
            html_string = '<html></html>'
        clean_html_string = self.clean_function(html_string)
        clean_xhtml_string = clean.html_to_xhtml(clean_html_string)
        if title:
            pass
        else:
            try:
                if request_object:
                    root = BeautifulSoup(html_string, 'html.parser')
                    meta_encoding = hole_meta_encoding(root)
                    if meta_encoding and (meta_encoding.lower() != 'utf-8'):
                        #print('Encoding to meta encoding: ' + repr(meta_encoding))
                        request_object.encoding = meta_encoding
                        html_string = request_object.text
                        root = BeautifulSoup(html_string, 'html.parser')
                        clean_html_string = self.clean_function(html_string)
                        clean_xhtml_string = clean.html_to_xhtml(clean_html_string)
                else:
                    root = BeautifulSoup(html_string, 'html.parser')
                title_node = root.title
                if title_node is not None:
                    #title = unicode(title_node.string)
                    title = title_node.string
                else:
                    raise ValueError
            except (IndexError, ValueError):
                title = 'Ebook Chapter'
        return Chapter(clean_xhtml_string, title, url)


